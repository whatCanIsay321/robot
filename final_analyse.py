import os
import json
from openai import OpenAI
from utils.file_helper import MarkdownTokenizerTool
from utils.extract_json import extract_single_json

# ===========================
# ğŸ”¹ åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
# ===========================
client = OpenAI(
    api_key="sk-dcb3caa7963645669e3205cae1f39464",
    base_url="https://api.deepseek.com"
)


# =======================================================
# ğŸ§  1ï¸âƒ£ æŠ½å–å‡½æ•°ï¼šä» Markdown å—ä¸­æå–å±‚çº§ç»“æ„
# =======================================================
def analyze_md_tree_with_deepseek(previous_structure, md_text):
    """è°ƒç”¨ DeepSeek æ¨¡å‹æŠ½å–å½“å‰å—çš„ç»“æ„"""

    prompt = f'''ğŸ¤– Role  
ä½ æ˜¯ä¸€å **Markdown æ–‡æ¡£ç»“æ„å¢é‡åˆ†æåŠ©æ‰‹**ï¼Œè´Ÿè´£æ ¹æ®è¾“å…¥æ–‡æœ¬è‡ªåŠ¨æ›´æ–°æ–‡æ¡£çš„ç»“æ„ä¿¡æ¯ã€‚  
æ–‡æ¡£ç»“æ„ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼š  
1. `ç›®å½•ç»“æ„ï¼ˆtocï¼‰`ï¼šä¿ç•™åŸæ–‡çš„ç›®å½•æ–‡æœ¬ï¼›  
2. `æ ‡é¢˜å±‚çº§ç»“æ„ï¼ˆoutlineï¼‰`ï¼šç”± Markdown æ ‡é¢˜ï¼ˆ#ã€##ã€### â€¦ï¼‰ç»„æˆçš„å±‚çº§æ ‘ã€‚  

---

# ğŸ’¬ ä»»åŠ¡ç›®æ ‡
æ ¹æ®è¾“å…¥ï¼š
- `previous_structure`ï¼šä¸Šä¸€æ¬¡å¤„ç†åçš„ç»“æ„ï¼ˆåŒ…å« toc ä¸ outlineï¼‰ï¼›  
- `current_chunk`ï¼šå½“å‰æ–°å¢çš„ Markdown æ–‡æœ¬ï¼›  

åˆ†æå½“å‰å—ä¸­çš„å˜åŒ–ï¼Œå¹¶åœ¨ä¸ä¸¢å¤±æ—§æ•°æ®çš„å‰æä¸‹ï¼š
- **å¢é‡æ›´æ–°**ç›®å½•å†…å®¹ï¼ˆè‹¥æ£€æµ‹åˆ°ç›®å½•ç« èŠ‚ï¼‰ï¼›  
- **å¢é‡æ›´æ–°**æ ‡é¢˜å±‚çº§ç»“æ„ï¼›  
- ä¿æŒå±‚çº§è¿ç»­ã€æ— é‡å¤ã€‚

---

# âš™ï¸ è§„åˆ™

## 1ï¸âƒ£ ç›®å½•æ£€æµ‹ï¼ˆTOC æ›´æ–°ï¼‰
- è‹¥æ£€æµ‹åˆ°â€œç›®å½•â€ã€â€œContentsâ€ã€â€œTable of Contentsâ€ç­‰å…³é”®è¯ï¼š  
  - æå–è¯¥éƒ¨åˆ†å®Œæ•´åŸæ–‡ä½œä¸ºæ–°çš„ç›®å½•å†…å®¹ï¼›  
  - è‹¥ä¹‹å‰å·²æœ‰ç›®å½•ï¼Œåˆ™è¿›è¡Œ**åˆå¹¶æˆ–æ›´æ–°**ï¼ˆä¿ç•™å…¨éƒ¨ç‹¬ç«‹ç›®å½•æ–‡æœ¬ï¼‰ï¼›  
  - ç›®å½•ä¸å‚ä¸æ ‡é¢˜å±‚çº§ç»“æ„åˆ†æã€‚

## 2ï¸âƒ£ æ ‡é¢˜å±‚çº§æ›´æ–°ï¼ˆOutline æ›´æ–°ï¼‰
- è¯†åˆ« Markdown æ ‡é¢˜ï¼ˆ# è‡³ ######ï¼‰ï¼›  
- ä»…æ–°å¢ `current_chunk` ä¸­çš„æ–°æ ‡é¢˜ï¼›  
- è‹¥æ ‡é¢˜å»¶ç»­ä¸Šå±‚ç»“æ„ï¼ˆä¾‹å¦‚ä¸Šä¸€éƒ¨åˆ†ä»¥ â€œ2.3â€ ç»“æŸï¼Œæœ¬æ®µä» â€œ2.3.1â€ å¼€å§‹ï¼‰ï¼Œ  
  è‡ªåŠ¨æŒ‚è½½åˆ°æ­£ç¡®çš„çˆ¶çº§ä¸‹ï¼›  
- æŒ‰æ–‡æœ¬å‡ºç°é¡ºåºæ„å»ºï¼Œä¸é‡æ’ã€ä¸ä¸¢å¤±ã€‚

## 3ï¸âƒ£ è¾“å‡ºè¦æ±‚
- è¾“å‡º **å®Œæ•´çš„æ›´æ–°åç»“æ„**ï¼ŒåŒ…å«ä¸¤éƒ¨åˆ†ï¼š  
  1. `æ£€æµ‹åˆ°çš„ç›®å½•`ï¼ˆè‹¥æœ‰åˆ™ä¿ç•™åŸæ–‡ï¼›å¯åŒ…å«å¤šæ®µç›®å½•ï¼‰ï¼›  
  2. `åˆå¹¶åçš„æ ‡é¢˜å±‚çº§ç»“æ„`ã€‚  
- ä½¿ç”¨ Markdown å±‚çº§æ ¼å¼è¡¨ç¤ºç»“æ„ï¼š
  ```markdown
  # ä¸€çº§æ ‡é¢˜
    - äºŒçº§æ ‡é¢˜
      - ä¸‰çº§æ ‡é¢˜
  ```
- ä¸è¾“å‡º JSONã€ä¸è§£é‡Šã€ä¸æ·»åŠ è¯´æ˜ã€‚

---

# ğŸ“¥ è¾“å…¥æ ¼å¼
```
=== previous_structure ===
{previous_structure if previous_structure else "æ— "}

=== current_chunk ===
{md_text}
```

---

# ğŸ“¤ è¾“å‡ºæ ¼å¼
```
æ£€æµ‹åˆ°çš„ç›®å½•ï¼š
ï¼ˆè‹¥å­˜åœ¨ç›®å½•åˆ™ä¿ç•™åŸæ–‡ï¼‰

# ä¸€çº§æ ‡é¢˜
  - äºŒçº§æ ‡é¢˜
    - ä¸‰çº§æ ‡é¢˜
```

'''

    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    content = response.choices[0].message.content.strip()
    try:

        return content
    except Exception:
        print("âš ï¸ æ¨¡å‹è¾“å‡ºéçº¯JSONï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ï¼š\n", content)
        return None

if __name__ == "__main__":
    model_path = r"D:\PycharmProjects\robot\utils\tokenizer"
    cleaned_path = r"D:\PycharmProjects\robot\raw_data\è”ç»œä¸­å¿ƒåŠäº‹æŒ‡å—åŠå¸¸è§é—®é¢˜ç™¾é—®ç™¾ç­”_cleaned.md"

    tool = MarkdownTokenizerTool(model_path)
    chunks = tool.chunk_until_token_limit(cleaned_path, max_tokens=2048)
    previous_structure = None  # åˆå§‹ä¸ºç©º

    for idx, chunk in enumerate(chunks, 1):
        print(f"\n=== ğŸ§© æ­£åœ¨åˆ†æç¬¬ {idx}/{len(chunks)} å— ===")
        result = analyze_md_tree_with_deepseek(previous_structure, chunk)


        # Step 2ï¸âƒ£: å¦‚æœä¸æ˜¯ç¬¬ä¸€å—ï¼Œç”¨å¤§æ¨¡å‹æ™ºèƒ½åˆå¹¶

        previous_structure = result

        # Step 3ï¸âƒ£: ä¿å­˜ä¸­é—´ç»“æœ
        with open(f"merged_progress_{idx}.md", "a", encoding="utf-8") as f:
            f.write(previous_structure + "\n")
        # with open(f"merged_progress_{idx}.json", "w", encoding="utf-8") as f:
        #     json.dump(previous_structure, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç¬¬ {idx} å—å¤„ç†å®Œæˆï¼Œç»“æ„å·²æ›´æ–°ã€‚")

