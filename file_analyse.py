# <<<<<<< HEAD
# # from markdown_it.rules_block import heading
# # from openai import OpenAI
# # import json
# # from utils.file_helper import MarkdownTokenizerTool
# # # å¦‚æœä½ æ˜¯è‡ªå»º deepseek æœåŠ¡ / æœ¬åœ° vLLM / DashScope æ¥å£ï¼Œè¯·æ”¹æˆå¯¹åº” base_url
# # client = OpenAI(
# #     api_key="sk-dcb3caa7963645669e3205cae1f39464",
# #     base_url="https://api.deepseek.com"
# # )
# #
# #
# # previous_structure=None
# # # ========== 2. Markdown æ•°æ® ==========
# # md_text = ''''''
# #
# # # ========== 3. Prompt æ„é€  ==========
# # # âœ… ä½¿ç”¨ f-string æ¥æ’å…¥ md_text
# # prompt = f"""
# # ä½ æ˜¯ä¸€å Markdown æ–‡æ¡£ç»“æ„åˆ†æåŠ©æ‰‹ã€‚
# #
# # ã€ä»»åŠ¡ç›®æ ‡ã€‘
# # æˆ‘ä¼šåˆ†æ®µæä¾› Markdown æ–‡æœ¬ï¼ˆcurrent_chunkï¼‰ï¼Œè¯·ä½ ä»æœ¬æ®µä¸­**æŠ½å–æ–°çš„æ ‡é¢˜å±‚çº§ç»“æ„**ï¼Œå¹¶æ„å»ºç›®å½•æ ‘ã€‚
# # ä½ éœ€è¦ç»“åˆä¸Šä¸€æ®µçš„ç»“æ„ï¼ˆprevious_structureï¼‰æ¥ä¿æŒå±‚çº§è¿ç»­æ€§ï¼Œä½†ä¸èƒ½é‡å¤å‰ä¸€æ®µå·²æŠ½å–çš„å†…å®¹ã€‚
# #
# # ã€æŠ½å–è§„åˆ™ã€‘
# # 1. åªå¤„ç†å½“å‰æ®µï¼ˆcurrent_chunkï¼‰ä¸­çš„æ–°å†…å®¹ï¼Œä¸è¦é‡å¤ previous_structure ä¸­å·²æœ‰çš„æ ‡é¢˜ã€‚
# # 2. å¦‚æœå‘ç°æ ‡é¢˜å±‚çº§å»¶ç»­è‡ªä¸Šä¸€æ®µï¼ˆä¾‹å¦‚ä¸Šä¸€æ®µä»¥ "1.2" ç»“æŸï¼Œå½“å‰æ®µä» "1.2.1" å¼€å§‹ï¼‰ï¼Œåº”æ­£ç¡®åµŒå…¥å¯¹åº”çš„ä¸Šå±‚æ ‡é¢˜ä¸‹ã€‚
# # 3. å¦‚æœæ–‡æœ¬ä¸­å­˜åœ¨â€œç›®å½•â€ã€â€œContentsâ€ã€â€œTable of Contentsâ€ç­‰éƒ¨åˆ†ï¼Œè¯·å°†è¯¥éƒ¨åˆ†**å•ç‹¬ä¿å­˜**åˆ° "detected_toc" å­—æ®µä¸­ï¼Œä¸å‚ä¸ç»“æ„æ ‘æ„å»ºã€‚
# # 4. è¾“å‡ºç»“æœä¸­å¿…é¡»åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š
# #    - "detected_toc"ï¼šä¿å­˜åŸæ–‡ä¸­ç›®å½•éƒ¨åˆ†çš„åŸå§‹æ–‡æœ¬ï¼›
# #    - "new_structure"ï¼šå½“å‰æ®µæ–°å¢çš„æ ‡é¢˜å±‚çº§æ ‘ï¼ˆä¸åŒ…å«é‡å¤å†…å®¹ï¼‰ã€‚
# # 5. æ¯ä¸ªèŠ‚ç‚¹éƒ½å¿…é¡»åŒ…å« "children" é”®ï¼Œå³ä½¿ä¸ºç©ºå¯¹è±¡ã€‚
# # 6. æŒ‰æ ‡é¢˜åœ¨æ–‡ä¸­å‡ºç°çš„é¡ºåºæ„å»ºå±‚çº§ï¼Œä¸è¦é‡æ–°æ’åºã€‚
# # 7. è¾“å‡ºå¿…é¡»ä¸º**ä¸¥æ ¼ JSON æ ¼å¼**ï¼Œä¸è¦é™„å¸¦è¯´æ˜ã€æ³¨é‡Šæˆ–å¤šä½™æ–‡æœ¬ã€‚
# #
# # ã€è¾“å‡ºæ ¼å¼ã€‘
# # {{
# #   "detected_toc": {{
# #     "raw_text": "ç›®å½•åŸæ–‡æ–‡æœ¬ï¼ˆè‹¥æ— åˆ™ä¸º nullï¼‰"
# #   }},
# #   "new_structure": {{
# #     "æ ‡é¢˜1": {{
# #       "children": {{
# #         "å­æ ‡é¢˜1": {{"children": {{}}}},
# #         "å­æ ‡é¢˜2": {{"children": {{}}}}
# #       }}
# #     }}
# #   }}
# # }}
# #
# # ã€è¾“å…¥æ•°æ®ã€‘
# # === ä¸Šä¸€æ®µå·²æŠ½å–çš„å±‚çº§ç»“æ„ ===
# # {previous_structure}
# #
# # === å½“å‰æ®µ Markdown æ–‡æœ¬ ===
# # {md_text}
# #
# # ã€è¾“å‡ºè¦æ±‚ã€‘
# # - åªè¾“å‡ºåˆæ³• JSONã€‚
# # - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚
# # - JSON å¿…é¡»å¯ä»¥ç›´æ¥è§£æã€‚
# # """
# #
# #
# #
# #
# # # ========== 4. è°ƒç”¨ DeepSeek æ¨¡å‹ ==========
# # def analyze_md_tree_with_deepseek(prompt: str):
# #     response = client.chat.completions.create(
# #         model="deepseek-chat",  # æˆ– deepseek-coder / DeepSeek-R1-Distill-Llama-70B
# #         messages=[{"role": "user", "content": prompt}],
# #         temperature=0
# #     )
# #
# #     content = response.choices[0].message.content.strip()
# #     try:
# #         tree = json.loads(content)
# #         return tree
# #     except Exception:
# #         print("âš ï¸ æ¨¡å‹è¾“å‡ºéçº¯JSONï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ï¼š\n", content)
# #         return None
# #
# #
# # # ========== 5. æ‰§è¡Œå¹¶æ‰“å°ç»“æœ ==========
# # if __name__ == "__main__":
# #     model_path = r"D:\PycharmProjects\robot\utils\tokenizer"
# #
# #     tool = MarkdownTokenizerTool(model_path)
# #     cleaned_path = r'D:\PycharmProjects\robot\raw_data\è”ç»œä¸­å¿ƒåŠäº‹æŒ‡å—åŠå¸¸è§é—®é¢˜ç™¾é—®ç™¾ç­”_cleaned.md'
# #     chunks = tool.chunk_until_token_limit(cleaned_path, max_tokens=2048)
# #
# #
# #     result = analyze_md_tree_with_deepseek(prompt)
# #     if result:
# #         print(json.dumps(result, ensure_ascii=False, indent=2))
# import os
# import json
# from copy import deepcopy
# from openai import OpenAI
# from utils.file_helper import MarkdownTokenizerTool
#
#
# # ========== DeepSeek å®¢æˆ·ç«¯ ==========
# =======
# from markdown_it.rules_block import heading
# from openai import OpenAI
# import json
#
# # å¦‚æœä½ æ˜¯è‡ªå»º deepseek æœåŠ¡ / æœ¬åœ° vLLM / DashScope æ¥å£ï¼Œè¯·æ”¹æˆå¯¹åº” base_url
# >>>>>>> b6517ef668d9a64ccbb8ca43ac3797774a835347
# client = OpenAI(
#     api_key="sk-dcb3caa7963645669e3205cae1f39464",
#     base_url="https://api.deepseek.com"
# )
# <<<<<<< HEAD
#
#
# # =======================================================
# # ğŸ§© ç»“æ„åˆå¹¶å·¥å…·
# # =======================================================
#
#
#
#
#
#
# # =======================================================
# # ğŸ§  æ¨¡å‹è°ƒç”¨å‡½æ•°
# # =======================================================
# def analyze_md_tree_with_deepseek(previous_structure, md_text):
#     """è°ƒç”¨ DeepSeek åˆ†æå½“å‰å—"""
#     prompt = f"""ä½ æ˜¯ä¸€å Markdown æ–‡æ¡£ç»“æ„åˆ†æåŠ©æ‰‹ã€‚
#
# ã€ä»»åŠ¡ç›®æ ‡ã€‘
# æˆ‘ä¼šåˆ†æ®µæä¾› Markdown æ–‡æœ¬ï¼ˆcurrent_chunkï¼‰ï¼Œè¯·ä½ ä»æœ¬æ®µä¸­**æŠ½å–æ–°çš„æ ‡é¢˜å±‚çº§ç»“æ„**ï¼Œå¹¶æ„å»ºç›®å½•æ ‘ã€‚
# ä½ éœ€è¦ç»“åˆä¸Šä¸€æ®µçš„ç»“æ„ï¼ˆprevious_structureï¼‰æ¥ä¿æŒå±‚çº§è¿ç»­æ€§ï¼Œä½†ä¸èƒ½é‡å¤å‰ä¸€æ®µå·²æŠ½å–çš„å†…å®¹ã€‚
#
# ã€æŠ½å–è§„åˆ™ã€‘
# 1. åªå¤„ç†å½“å‰æ®µï¼ˆcurrent_chunkï¼‰ä¸­çš„æ–°å†…å®¹ï¼Œä¸è¦é‡å¤ previous_structure ä¸­å·²æœ‰çš„æ ‡é¢˜ã€‚
# 2. å¦‚æœå‘ç°æ ‡é¢˜å±‚çº§å»¶ç»­è‡ªä¸Šä¸€æ®µï¼ˆä¾‹å¦‚ä¸Šä¸€æ®µä»¥ "1.2" ç»“æŸï¼Œå½“å‰æ®µä» "1.2.1" å¼€å§‹ï¼‰ï¼Œåº”æ­£ç¡®åµŒå…¥å¯¹åº”çš„ä¸Šå±‚æ ‡é¢˜ä¸‹ã€‚
# 3. å¦‚æœæ–‡æœ¬ä¸­å­˜åœ¨â€œç›®å½•â€ã€â€œContentsâ€ã€â€œTable of Contentsâ€ç­‰éƒ¨åˆ†ï¼Œè¯·å°†è¯¥éƒ¨åˆ†**å•ç‹¬ä¿å­˜**åˆ° "detected_toc" å­—æ®µä¸­ï¼Œä¸å‚ä¸ç»“æ„æ ‘æ„å»ºã€‚
# 4. è¾“å‡ºç»“æœä¸­å¿…é¡»åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š
#    - "detected_toc"ï¼šä¿å­˜åŸæ–‡ä¸­ç›®å½•éƒ¨åˆ†çš„åŸå§‹æ–‡æœ¬ï¼›
#    - "new_structure"ï¼šå½“å‰æ®µæ–°å¢çš„æ ‡é¢˜å±‚çº§æ ‘ï¼ˆä¸åŒ…å«é‡å¤å†…å®¹ï¼‰ã€‚
# 5. æ¯ä¸ªèŠ‚ç‚¹éƒ½å¿…é¡»åŒ…å« "children" é”®ï¼Œå³ä½¿ä¸ºç©ºå¯¹è±¡ã€‚
# 6. æŒ‰æ ‡é¢˜åœ¨æ–‡ä¸­å‡ºç°çš„é¡ºåºæ„å»ºå±‚çº§ï¼Œä¸è¦é‡æ–°æ’åºã€‚
# 7. è¾“å‡ºå¿…é¡»ä¸º**ä¸¥æ ¼ JSON æ ¼å¼**ï¼Œä¸è¦é™„å¸¦è¯´æ˜ã€æ³¨é‡Šæˆ–å¤šä½™æ–‡æœ¬ã€‚
#
# ã€è¾“å‡ºæ ¼å¼ã€‘
# {{
#   "detected_toc": {{
#     "raw_text": "ç›®å½•åŸæ–‡æ–‡æœ¬ï¼ˆè‹¥æ— åˆ™ä¸º nullï¼‰"
#   }},
#   "new_structure": {{
#     "æ ‡é¢˜1": {{
#       "children": {{
#         "å­æ ‡é¢˜1": {{"children": {{}}}},
#         "å­æ ‡é¢˜2": {{"children": {{}}}}
# =======
# # ========== 2. Markdown æ•°æ® ==========
# md_text = """L1 | 1.1 æ¸ é“æ‹›å‹Ÿåˆä¼™äººä¿¡æ¯åé¦ˆ | [0, 19)
# L1 | 1.1.1 å¯Œå®¶æ±‡çš„ä¿¡æ¯æ¨å¹¿å’Œé€‚ç”¨ä¸šåŠ¡èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ | [19, 87)
# L1 | Aã€ç™»å½•æ–¹å¼ï¼š | [87, 204)
# L1 | Bã€åˆä¼™äººç»‘å®šæ¸ é“ä¼™ä¼´çš„ä¸‰ç§æ–¹å¼ | [204, 385)
# L1 | Cã€æ³¨æ„äº‹é¡¹ï¼š | [385, 854)
# L1 | 1.2 åˆä¼™äººæ³¨å†Œæ³¨æ„äº‹é¡¹ | [854, 871)
# L1 | 1.2.1 åˆä¼™äººè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ | [871, 970)
# L1 | 1.2.2 åˆä¼™äººæ³¨å†Œæ­¥éª¤ | [970, 1124)
# L1 | 1.2.3 åˆä¼™äººå®Œæˆç­¾çº¦çš„å…·ä½“æ ‡å‡† | [1124, 1311)
# L1 | 1.3 æ¸ é“ä¼™ä¼´ç›¸å…³é—®é¢˜ | [1311, 1327)
# L1 | 1.3.1 æ¸ é“ä¼™ä¼´å¦‚ä½•æ³¨å†Œä¸ºå¯Œå®¶æ±‡åˆä¼™äºº | [1327, 1482)
# L1 | 1.3.2 ç³»ç»Ÿæç¤ºå­è´¦æˆ·ä¸èƒ½æ³¨å†Œç›´è¥åˆä¼™äºº | [1482, 1536)
# L1 | 1.3.3 æ¸ é“ä¼™ä¼´æœ‰å½•å•åŠäº¤ä»˜éœ€æ±‚ | [1536, 1781)
# L1 | 1.4 çº¿ç´¢å½•å…¥ | [1781, 1793)
# L1 | 1.4.1 åˆä¼™äººçº¿ç´¢å½•å…¥çš„æ¡ä»¶ | [1793, 1824)
# L1 | 1.4.2 æ¥å•åŒºåŸŸèŒƒå›´å’Œçº¿ç´¢çš„ç°å‹˜èŒƒå›´ä¸ä¸€è‡´ï¼Œæ˜¯å¦å¯ä»¥åšçº¿ç´¢å½•å…¥ | [1824, 1909)
# L1 | 1.5 ç»“ç®—ç›¸å…³é—®é¢˜ | [1909, 1923)
# L1 | 1.5.1 çµæ´»ç”¨å·¥å’Œå¯¹å…¬ä»˜æ¬¾çš„åŒºåˆ« | [1923, 2045)
# L1 | 1.5.2 ä¸šåŠ¡è´¹ç”¨åŠç¨ç‚¹ | [2045, 2208)
# L1 | 1.5.3 ä¿¡æ¯ä¸ä¸€è‡´ï¼Œå¯ä»¥ç»“ç®—å— | [2208, 2267)
# L1 | 1.5.4 è´¹ç”¨ç»“ç®—ä»¥å“ªä¸ªæ—¶é—´ç‚¹ä¸ºå‡†äº«å—æ”¿ç­– | [2267, 2342)
# L1 | 1.5.5 å…¶ä»–è´¹ç”¨æ˜ç»†åŠç¨ç‚¹ | [2342, 2383)
# """
#
# # ========== 3. Prompt æ„é€  ==========
# # âœ… ä½¿ç”¨ f-string æ¥æ’å…¥ md_text
# prompt = f"""
# ä½ æ˜¯ä¸€å Markdown æ–‡æ¡£ç»“æ„åˆ†æåŠ©æ‰‹ã€‚
#
# ä»¥ä¸‹æ˜¯ä¸€ä»½æ ‡é¢˜åˆ—è¡¨ï¼Œæ¯ä¸€è¡ŒåŒ…å«ç¼–å·ã€æ ‡é¢˜ã€ä»¥åŠåœ¨åŸæ–‡ä¸­çš„ä½ç½®åŒºé—´ã€‚
#
# è¯·æ ¹æ®è¿™äº›æ ‡é¢˜çš„ç¼–å·å’Œé€»è¾‘é¡ºåºï¼Œç”Ÿæˆä¸€ä¸ªåµŒå¥—çš„ JSON ç»“æ„ï¼Œè¡¨ç¤ºå®ƒä»¬çš„å±‚çº§å…³ç³»ã€‚
#
# è¾“å‡ºè¦æ±‚ï¼š
# - ä»¥çº¯ JSON æ ¼å¼è¾“å‡ºï¼›
# - æ¯ä¸ªèŠ‚ç‚¹çš„é”®ä¸ºâ€œç¼–å· + ç©ºæ ¼ + æ ‡é¢˜â€ï¼›
# - æ¯ä¸ªèŠ‚ç‚¹çš„å€¼ä¸ºä¸€ä¸ªå¯¹è±¡ï¼ŒåªåŒ…å«ä¸€ä¸ªé”® "children"ï¼›
# - "children" çš„å€¼æ˜¯åŒæ ·ç»“æ„çš„å­èŠ‚ç‚¹å¯¹è±¡ï¼›
# - æ— å­èŠ‚ç‚¹æ—¶ï¼Œ"children" ä¸ºç©ºå¯¹è±¡ï¼›
# - ä¸è¾“å‡ºä»»ä½•è¯´æ˜æˆ–è§£é‡Šã€‚
#
# ç¤ºä¾‹è¾“å‡ºï¼š
# {{
#   "1.1 æ¸ é“æ‹›å‹Ÿåˆä¼™äººä¿¡æ¯åé¦ˆ": {{
#     "children": {{
#       "1.1.1 å¯Œå®¶æ±‡çš„ä¿¡æ¯æ¨å¹¿å’Œé€‚ç”¨ä¸šåŠ¡èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ": {{
#         "children": {{
#           "Aã€ç™»å½•æ–¹å¼ï¼š": {{"children": {{}}}},
#           "Bã€åˆä¼™äººç»‘å®šæ¸ é“ä¼™ä¼´çš„ä¸‰ç§æ–¹å¼": {{"children": {{}}}},
#           "Cã€æ³¨æ„äº‹é¡¹ï¼š": {{"children": {{}}}}
#         }}
# >>>>>>> b6517ef668d9a64ccbb8ca43ac3797774a835347
#       }}
#     }}
#   }}
# }}
#
# <<<<<<< HEAD
# ã€è¾“å…¥æ•°æ®ã€‘
# === ä¸Šä¸€æ®µå·²æŠ½å–çš„å±‚çº§ç»“æ„ ===
# {json.dumps(previous_structure, ensure_ascii=False) if previous_structure else "null"}
#
# === å½“å‰æ®µ Markdown æ–‡æœ¬ ===
# {md_text}
#
# ã€è¾“å‡ºè¦æ±‚ã€‘
# - åªè¾“å‡ºåˆæ³• JSONã€‚
# - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚
# - JSON å¿…é¡»å¯ä»¥ç›´æ¥è§£æã€‚
# """
#
#     response = client.chat.completions.create(
#         model="deepseek-chat",
# =======
# ä¸‹é¢æ˜¯è¾“å…¥æ•°æ®ï¼š
# {md_text}
# """
#
# # ========== 4. è°ƒç”¨ DeepSeek æ¨¡å‹ ==========
# def analyze_md_tree_with_deepseek(prompt: str):
#     response = client.chat.completions.create(
#         model="deepseek-chat",  # æˆ– deepseek-coder / DeepSeek-R1-Distill-Llama-70B
# >>>>>>> b6517ef668d9a64ccbb8ca43ac3797774a835347
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0
#     )
#
#     content = response.choices[0].message.content.strip()
#     try:
#         tree = json.loads(content)
#         return tree
#     except Exception:
#         print("âš ï¸ æ¨¡å‹è¾“å‡ºéçº¯JSONï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹ï¼š\n", content)
#         return None
#
#
# <<<<<<< HEAD
# # =======================================================
# # ğŸš€ ä¸»æµç¨‹ï¼šå¾ªç¯å¤„ç† + å®æ—¶åˆå¹¶
# # =======================================================
# if __name__ == "__main__":
#     model_path = r"D:\PycharmProjects\robot\utils\tokenizer"
#     cleaned_path = r"D:\PycharmProjects\robot\raw_data\è”ç»œä¸­å¿ƒåŠäº‹æŒ‡å—åŠå¸¸è§é—®é¢˜ç™¾é—®ç™¾ç­”_cleaned.md"
#
#     tool = MarkdownTokenizerTool(model_path)
#     chunks = tool.chunk_until_token_limit(cleaned_path, max_tokens=2048)
#
#     merged_structure = None  # âœ… ä»ç©ºå¼€å§‹
#
#     for idx, chunk in enumerate(chunks, 1):
#         print(f"\n=== ğŸ§© æ­£åœ¨åˆ†æç¬¬ {idx}/{len(chunks)} å— ===")
#
#         # è°ƒç”¨æ¨¡å‹ï¼ˆä¼ å…¥å½“å‰åˆå¹¶ç»“æ„ä½œä¸º previous_structureï¼‰
#         result = analyze_md_tree_with_deepseek(merged_structure, chunk)
#         if not result:
#             print(f"âš ï¸ ç¬¬ {idx} å—æ¨¡å‹è¾“å‡ºå¼‚å¸¸ï¼Œè·³è¿‡ã€‚")
#             continue
#
#         # âœ… åˆå¹¶æœ¬è½®ç»“æ„
#         if idx > 1:
#             merged_structure = merge_two_structures(merged_structure, result)
#         else:
#             merged_structure = result
#
#         # ä¿å­˜ä¸­é—´ç»“æœï¼ˆé˜²æ­¢å´©æºƒä¸¢å¤±ï¼‰
#         with open("merged_progress.json", "w", encoding="utf-8") as f:
#             json.dump(merged_structure, f, ensure_ascii=False, indent=2)
#
#         print(f"âœ… å·²åˆå¹¶åˆ°ç¬¬ {idx} å—ï¼Œå½“å‰ç»“æ„å·²æ›´æ–°ã€‚")
#
#     # è¾“å‡ºæœ€ç»ˆç»“æœ
#     with open("final_merged_markdown_structure.json", "w", encoding="utf-8") as f:
#         json.dump(merged_structure, f, ensure_ascii=False, indent=2)
#
#     print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼Œæœ€ç»ˆåˆå¹¶ç»“æ„å·²ä¿å­˜åˆ° final_merged_markdown_structure.json âœ…")
# =======
# # ========== 5. æ‰§è¡Œå¹¶æ‰“å°ç»“æœ ==========
# if __name__ == "__main__":
#     result = analyze_md_tree_with_deepseek(prompt)
#     if result:
#         print(json.dumps(result, ensure_ascii=False, indent=2))
# >>>>>>> b6517ef668d9a64ccbb8ca43ac3797774a835347
